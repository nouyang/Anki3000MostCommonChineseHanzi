{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "import regex\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "一: [yī] one, a little; 第一 dì-yī first, primary; 看一看 kànyīkàn have a (quick) look at<BR>[yí] (used before tone #4); 一个人 yí gè rén one person; 一定 yídìng certain; 一样 yíyàng same; 一月yíyuè January<BR>[yì] (used before tones #2 and #3); 一点儿 yìdiǎnr a little; 一些 yìxiē some<BR>{Compare with 幺(F么) yāo, which also means 'one'<BR><BR>rank = 2\n",
      "\n",
      "第一; 看一看; 一个人; 一定; 一样; 一月; 一点儿; 一些 \n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "######################## \n",
    "# Prototype formatter: take out example words from definition \n",
    "######################## \n",
    "\n",
    "#result = regex.sub(ur'[^\\p{Latin}]', u'', text)\n",
    "with open('0-500.txt') as f:\n",
    "        #text = f.readline()\n",
    "        lines = f.readlines()\n",
    "        #print(lines[:5])\n",
    "        text = lines[1]\n",
    "        print(text)\n",
    "        text = text[1:] #remove first character (which is the hanzi)\n",
    "        text = text.split('{')[0]\n",
    "        #string.punctuation\n",
    "        r = regex.sub(r'[.]{3,}', u'…', text)\n",
    "        r = r.replace('<BR>', ';')\n",
    "        r = regex.sub(r'[\\p{Latin}]', u'', r)\n",
    "        r = re.sub(r\"[^\\w^;^…^!]+\",'', r) # replace not-word charatesr with empty string\n",
    "        r = re.sub(r\"[^\\w^…]{2,}\",'; ', r) # replace not-word charatesr with empty string\n",
    "        r = re.sub(r\"[0-9]+\",'', r) # replace numbers\n",
    "        r = re.sub(r\"^[^\\w]+\",'', r) # replace beginning not word chars \n",
    "        r = r.replace(';;', ';') \n",
    "        r = r.replace(';', '; ') # add space between words\n",
    "        r = r.strip()\n",
    "        r = regex.sub(r'[.;]$', u' ', r) \n",
    "        #r = regex.sub(r'[;]', u'; ', r)\n",
    "        \n",
    "\n",
    "        #s = re.sub(r'[^\\w\\s]','',s)\n",
    "        print(r)\n",
    "        print('\\n---\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_words(hanzi, line):\n",
    "    line = line[1:] #remove first character (which is the hanzi)\n",
    "    line = line.split('{')[0] # remove \"{compare to \" information\n",
    "    r = regex.sub(r'[.]{3,}', u'…', line) # replace ellipsis so not removed later\n",
    "    r = r.replace('<BR>', ';')\n",
    "    r = regex.sub(r'[\\p{Latin}]', u'', r)\n",
    "    r = re.sub(r\"[^\\w^;^…^!]+\",'', r) # replace not-word charatesr with empty string\n",
    "    r = re.sub(r\"[^\\w^…]{2,}\",', ', r) # replace not-word charatesr with empty string\n",
    "    r = re.sub(r\"[0-9]+\",'', r) # replace numbers\n",
    "    r = re.sub(r\"^[^\\w]+\",'', r) # replace beginning not word chars \n",
    "    r = r.replace(';;', ';') \n",
    "    r = r.replace(';', '; ') # add space between words\n",
    "    r = r.strip()\n",
    "    r = regex.sub(r'[;,]$', u'', r) # remove comma or semicolon at end\n",
    "    words = r\n",
    "    r = r.replace(hanzi, f'<span class=examplehanzi>{hanzi}</span>')\n",
    "    bolded = r\n",
    "    #<div class=hanzi>\n",
    "    return words, bolded\n",
    "\n",
    "\n",
    "mydict = {}\n",
    "with open('concatenated.txt') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        hanzi, full_defn = line.split(':')\n",
    "        words, bolded = get_words(hanzi, line)\n",
    "        mydict[hanzi] = full_defn, words, bolded\n",
    "        \n",
    "        \n",
    "zein = pd.DataFrame.from_dict(mydict, orient='index', columns=['Zein.se definition', 'Example words', 'Formatted Words'])\n",
    "zein = zein.reset_index()\n",
    "zein.columns=['Hanzi', 'Zein.se definition', 'Example words', 'Formatted Words']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0-500.txt\n",
      " 1000-1500.txt\n",
      " 1500-2000.txt\n",
      " 2000-2500.txt\n",
      " 2500-3000.txt\n",
      " 500-1000.txt\n",
      "'Anki Chinese 3000 with example words - Reading for Import using Addon.csv'\n",
      "'Anki Chinese 3000 with example words.xlsx'\n",
      "'Anki Spreadsheet Import Chinese 3000 with Examples.xlsx'\n",
      " AnkiWebMostCommon3000.csv\n",
      " concatenated.txt\n",
      " MyEdit.csv\n",
      " nonlatin.ipynb\n",
      " output.csv\n",
      " README.md\n",
      " scraper.py\n",
      "Index(['Character', 'Traditional', 'Unnamed: 2', 'HSK', 'FrequencyRank',\n",
      "       'Unnamed: 5', 'Unnamed: 6', 'Pinyin 1', 'Pinyin 2', 'Definition'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Traditional</th>\n",
       "      <th>HSK</th>\n",
       "      <th>FrequencyRank</th>\n",
       "      <th>Pinyin 1</th>\n",
       "      <th>Pinyin 2</th>\n",
       "      <th>Definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>的</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>de</td>\n",
       "      <td>dí, dì</td>\n",
       "      <td>possessive, adjectival suffix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>一</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>yī</td>\n",
       "      <td>NaN</td>\n",
       "      <td>one; a, an; alone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>是</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>shì</td>\n",
       "      <td>NaN</td>\n",
       "      <td>indeed, yes, right; to be; demonstrative prono...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>不</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4</td>\n",
       "      <td>bù</td>\n",
       "      <td>fǒu, fōu</td>\n",
       "      <td>no, not; un-; negative prefix</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>了</td>\n",
       "      <td>瞭</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>le</td>\n",
       "      <td>liǎo</td>\n",
       "      <td>to finish; particle of completed action</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>颓</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2996</td>\n",
       "      <td>tuí</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ruined, decayed; disintegrate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>熏</td>\n",
       "      <td>熏 燻</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2997</td>\n",
       "      <td>xūn</td>\n",
       "      <td>xùn</td>\n",
       "      <td>smoke, fog, vapor; smoke, cure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>瑛</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2998</td>\n",
       "      <td>yīng</td>\n",
       "      <td>NaN</td>\n",
       "      <td>luster of gem; crystal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>颐</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2999</td>\n",
       "      <td>yí</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cheeks; jaw; chin; rear; to nourish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>忖</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000</td>\n",
       "      <td>cǔn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>guess, suppose, conjecture</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Character Traditional  HSK  FrequencyRank Pinyin 1   Pinyin 2  \\\n",
       "0            的         NaN  1.0              1       de     dí, dì   \n",
       "1            一         NaN  1.0              2       yī        NaN   \n",
       "2            是         NaN  1.0              3      shì        NaN   \n",
       "3            不         NaN  1.0              4       bù   fǒu, fōu   \n",
       "4            了        瞭     1.0              5       le       liǎo   \n",
       "...        ...         ...  ...            ...      ...        ...   \n",
       "2995         颓         NaN  NaN           2996      tuí        NaN   \n",
       "2996         熏       熏 燻    6.0           2997      xūn        xùn   \n",
       "2997         瑛         NaN  NaN           2998     yīng        NaN   \n",
       "2998         颐         NaN  NaN           2999       yí        NaN   \n",
       "2999         忖         NaN  NaN           3000      cǔn        NaN   \n",
       "\n",
       "                                             Definition  \n",
       "0                         possessive, adjectival suffix  \n",
       "1                                     one; a, an; alone  \n",
       "2     indeed, yes, right; to be; demonstrative prono...  \n",
       "3                         no, not; un-; negative prefix  \n",
       "4               to finish; particle of completed action  \n",
       "...                                                 ...  \n",
       "2995                      ruined, decayed; disintegrate  \n",
       "2996                     smoke, fog, vapor; smoke, cure  \n",
       "2997                             luster of gem; crystal  \n",
       "2998                cheeks; jaw; chin; rear; to nourish  \n",
       "2999                         guess, suppose, conjecture  \n",
       "\n",
       "[3000 rows x 7 columns]"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!ls\n",
    "df = pd.read_csv('AnkiWebMostCommon3000.csv')\n",
    "print(df.columns)\n",
    "df = df[['Character', 'Traditional', 'HSK', 'FrequencyRank', 'Pinyin 1', 'Pinyin 2', 'Definition']]\n",
    "df\n",
    "#df.columns=(['Hanzi', 'Traditional', 'Image URL',  'HSK', 'FrequencyRank', 'Pinyin', 'Pinyin2', 'Meaning', 'Notes'])\n",
    "#df.set_index('Character')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 11)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.concat([df, zein], axis=1)\n",
    "merged = df.merge(zein, left_on='Character', right_on='Hanzi', how='left')\n",
    "#print(df.iloc[0])\n",
    "#df.iloc[0]['Character'] == zein.iloc[0]['Name']\n",
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(329, 11)\n",
      "(0, 11)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Character</th>\n",
       "      <th>Traditional</th>\n",
       "      <th>HSK</th>\n",
       "      <th>FrequencyRank</th>\n",
       "      <th>Pinyin 1</th>\n",
       "      <th>Pinyin 2</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Hanzi</th>\n",
       "      <th>Zein.se definition</th>\n",
       "      <th>Example words</th>\n",
       "      <th>Formatted Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>乎</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "      <td>458</td>\n",
       "      <td>hū</td>\n",
       "      <td>hú</td>\n",
       "      <td>interrogative or exclamatory final particle</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>床</td>\n",
       "      <td>牀 床</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1068</td>\n",
       "      <td>chuáng</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bed, couch; framework, chassis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1642</th>\n",
       "      <td>辖</td>\n",
       "      <td>轄</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1643</td>\n",
       "      <td>xiá</td>\n",
       "      <td>NaN</td>\n",
       "      <td>linchpin of wheel; control</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1657</th>\n",
       "      <td>咬</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1658</td>\n",
       "      <td>yǎo</td>\n",
       "      <td>jiāo</td>\n",
       "      <td>bite, gnaw</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1814</th>\n",
       "      <td>歼</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1815</td>\n",
       "      <td>jiān</td>\n",
       "      <td>NaN</td>\n",
       "      <td>annihilate, wipe out, kill off</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>颓</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2996</td>\n",
       "      <td>tuí</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ruined, decayed; disintegrate</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>熏</td>\n",
       "      <td>熏 燻</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2997</td>\n",
       "      <td>xūn</td>\n",
       "      <td>xùn</td>\n",
       "      <td>smoke, fog, vapor; smoke, cure</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>瑛</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2998</td>\n",
       "      <td>yīng</td>\n",
       "      <td>NaN</td>\n",
       "      <td>luster of gem; crystal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>颐</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2999</td>\n",
       "      <td>yí</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cheeks; jaw; chin; rear; to nourish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>忖</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3000</td>\n",
       "      <td>cǔn</td>\n",
       "      <td>NaN</td>\n",
       "      <td>guess, suppose, conjecture</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Character Traditional  HSK  FrequencyRank Pinyin 1 Pinyin 2  \\\n",
       "457          乎         NaN  3.0            458       hū       hú   \n",
       "1067         床       牀 床    2.0           1068   chuáng      NaN   \n",
       "1642         辖        轄     6.0           1643      xiá      NaN   \n",
       "1657         咬         NaN  5.0           1658      yǎo     jiāo   \n",
       "1814         歼         NaN  NaN           1815     jiān      NaN   \n",
       "...        ...         ...  ...            ...      ...      ...   \n",
       "2995         颓         NaN  NaN           2996      tuí      NaN   \n",
       "2996         熏       熏 燻    6.0           2997      xūn      xùn   \n",
       "2997         瑛         NaN  NaN           2998     yīng      NaN   \n",
       "2998         颐         NaN  NaN           2999       yí      NaN   \n",
       "2999         忖         NaN  NaN           3000      cǔn      NaN   \n",
       "\n",
       "                                       Definition Hanzi Zein.se definition  \\\n",
       "457   interrogative or exclamatory final particle   NaN                NaN   \n",
       "1067               bed, couch; framework, chassis   NaN                NaN   \n",
       "1642                   linchpin of wheel; control   NaN                NaN   \n",
       "1657                                   bite, gnaw   NaN                NaN   \n",
       "1814               annihilate, wipe out, kill off   NaN                NaN   \n",
       "...                                           ...   ...                ...   \n",
       "2995                ruined, decayed; disintegrate   NaN                NaN   \n",
       "2996               smoke, fog, vapor; smoke, cure   NaN                NaN   \n",
       "2997                       luster of gem; crystal   NaN                NaN   \n",
       "2998          cheeks; jaw; chin; rear; to nourish   NaN                NaN   \n",
       "2999                   guess, suppose, conjecture   NaN                NaN   \n",
       "\n",
       "     Example words Formatted Words  \n",
       "457            NaN             NaN  \n",
       "1067           NaN             NaN  \n",
       "1642           NaN             NaN  \n",
       "1657           NaN             NaN  \n",
       "1814           NaN             NaN  \n",
       "...            ...             ...  \n",
       "2995           NaN             NaN  \n",
       "2996           NaN             NaN  \n",
       "2997           NaN             NaN  \n",
       "2998           NaN             NaN  \n",
       "2999           NaN             NaN  \n",
       "\n",
       "[329 rows x 11 columns]"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(merged[merged['Hanzi'].isna()].shape)\n",
    "print(merged[merged['Character'].isna()].shape)\n",
    "merged[merged['Traditional'].isna()]\n",
    "merged[merged['Hanzi'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged.to_csv('output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
